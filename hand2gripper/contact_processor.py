import os
import cv2
import numpy as np
import mediapy
import tqdm
from pathlib import Path
from typing import Union, List, Tuple

from hand2gripper_haco import HACOContactEstimator
from processor_config import ContactProcessorConfig, HandProcessorConfig
from utils.common import read_color_image, read_depth_image, _to_numpy

class ContactProcessor:
    def __init__(self, contact_processor_config: ContactProcessorConfig):
        # config
        self.contact_processor_config = contact_processor_config
        self.output_dir = self.contact_processor_config.processor_output_dir
        # contact estimator
        self.contact_estimator = HACOContactEstimator(backbone=self.contact_processor_config.backbone, checkpoint_path=self.contact_processor_config.checkpoint_path, experiment_dir=self.contact_processor_config.log_dir)
        # vis
        # save

    def _process_single_sample(self, sample_id: int, color_image: Union[str, np.ndarray], depth_image: Union[str, np.ndarray]) -> np.ndarray:
        # read image
        color = read_color_image(color_image)
        depth = read_depth_image(depth_image)

        # read_bbox (generated by HandProcessor)
        bboxes = self._read_bbox(sample_id)

        # predict contact
        ## contact_results: Dictionary containing contact results {'contact_mask': np.ndarray, 'contact_rendered': np.ndarray, 'crop_img': np.ndarray, 'raw_outputs': dict}
        for idx in range(len(bboxes)):
            contact_results = self.contact_estimator.predict_contact(color, bboxes[idx])
    
    def _read_bbox(self, sample_id: int) -> List[np.ndarray]:
        hand_processor_config = HandProcessorConfig()
        hand_processor_results_dir = hand_processor_config.hand_processor_results_dir
        # read sample_id_*.npz, {sample_id}_1.npz, {sample_id}_2.npz,...
        bboxes = []
        for file in os.listdir(hand_processor_results_dir):
            if file.startswith(f"{sample_id}_"):
                bbox = np.load(os.path.join(hand_processor_results_dir, file))['bbox']
                bboxes.append(bbox)
        return bboxes




if __name__ == '__main__':
    contact_processor_config = ContactProcessorConfig()
    contact_processor = ContactProcessor(contact_processor_config)
    video_path = "/home/yutian/projs/Hand2Gripper/hand2gripper/raw/0/video.mp4"
    depth_npy_path = "/home/yutian/projs/Hand2Gripper/hand2gripper/raw/0/depth.npy"
    video = mediapy.read_video(video_path)
    depth_npy = np.load(depth_npy_path)
    assert len(video) == len(depth_npy), "Number of frames in video and depth image must be the same"
    for idx in tqdm.tqdm(range(len(video)), desc="Contact Processor: Processing samples"):
        color_image = video[idx]
        depth_image = depth_npy[idx]  # meters
        contact_processor._process_single_sample(idx, color_image, depth_image)